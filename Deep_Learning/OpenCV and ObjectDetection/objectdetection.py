# -*- coding: utf-8 -*-
"""ObjectDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18yeF_3jKKPyJVFPtPpeJpYXiSRwiVF2w

# Lab3: Real time analysis and Pytorch

Table of Contents Step1. OpenCV and object detection 1.1. Video capturing 1.2. Digit recognition 1.3. Face recognition Step2. RNN and text classification Step3. Pytorch- optiona

# Step1. OpenCV and object detection
"""

#Install opencv package on python
# conda install -c conda-forge opencv

### 1.1. Video capturing

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

cap = cv2.VideoCapture(0)
while True:
 ret, frame= cap.read() # Forever it returns the frame and ret which is false or true
 #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #if you want to convert the color
 cv2.imshow('frame', frame)
 cv2.imshow('gray', gray) # to show the gray video

 if cv2.waitKey(1) & 0xFF == ord('q'): # If q is pressed stop
    break

cap.release()
cv2.destroyAllWindows()

"""## Step2. RNN and text classification

IMDB sentimental analysis movie review is one of the famous datasets for analyzing the  sentiments in reviews. This dataset contains the information of 25,000 review of movies (Website: http://ai.stanford.edu/~amaas/data/sentiment).
For this part of lab, we are using the IMDB dataset preloaded in Keras. Based on Keras document section: “Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative).  Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for
instance the integer "3" encodes the 3rd most frequent word in the data.”
For this part of lab, we are using the IMDB dataset preloaded in Keras. Based on Keras document  section: “Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for
instance the integer "3" encodes the 3rd most frequent word in the data.”
"""

#Import libraries
import numpy as np
from tensorflow.keras.datasets import imdb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing import sequence
# fix random seed for reproducibility
np.random.seed(7)

#Import dataset
top_words = 5000
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)

#Truncate and pad input sequences so they are all same length for modeling:
max_review_length = 500
X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)
X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)

"""### ***Q3: What is the meaning of “word embedding” in context of NLP?***

Word embedding is a process to generate dense vector representations for words that capture their semantic and syntactic properties. These representations can be used by machine learning algorithms to perfrom various NLP tasks (langage modeling, translation...)
"""

# Design model
embedding_vecor_length = 32
model = Sequential()
model.add(Embedding(top_words, embedding_vecor_length,input_length=max_review_length))
model.add(LSTM(100))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])
print(model.summary())
hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20,batch_size=64)

# Final evaluation of the model
scores = model.evaluate(X_test, y_test, verbose=0)
print("Accuracy: %.2f%%" % (scores[1]*100))

"""### ***Q4- Draw the learning curves and describe them***"""

import matplotlib.pyplot as plt

#Plot learning curves
plt.subplot(2,1,1)
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')

plt.subplot(2,1,2)
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')

"""Learning curves show high difference between training accuracy and validation accuracy, it is an indication of overfitting and failure to generalize well on new or unseen data.
In this case, the training accuracy has improved significantly, from 0.8 to 0.98, indicating that the model has learned the training data well. However, the validation accuracy has only slightly improved, reaching 0.85 at the 18th epoch, but then drops to 0.72 at the 20th epoch. This suggests that the model is overfitting on the training data and is failing to generalize well on the validation data.
Additionally, the training loss has dropped significantly from 0.42 to 0.05, while the validation loss has increased from 0.4 to 0.8. This further confirms the overfitting, as the training loss is decreasing while the validation loss is increasing.
To address this issue, let's apply dropout regularization.

### ***Q5- Add a dropout to see how the model changes***
"""

from tensorflow.keras.layers import Dropout

#Design new_model
new_model = Sequential()
new_model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))
new_model.add(LSTM(100))
new_model.add(Dropout(0.2))  # Add a dropout layer with rate 0.2
new_model.add(Dense(1, activation='sigmoid'))
new_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(new_model.summary())
hist = new_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=64)

#Final evaluation of the new_model
scores = new_model.evaluate(X_test, y_test, verbose=0)
print("Accuracy: %.2f%%" % (scores[1]*100))

#Plot learning curves
plt.subplot(2,1,1)
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('new_model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')

plt.subplot(2,1,2)
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('new_model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')

"""Learning curves show decrease in the difference between training accuracy and validation accuracy indicates that the model is now generalizing better to new data despite the fact that the overall accuracy haven't improved. Accuracy stayed at 85%.

### ***Q6- Add the CNN layer and evaluate the model.***
Now we want to combine LSTM and CNN. We want to add following code as the convolutional layer.
"""

from keras.layers import Conv1D, MaxPooling1D

#Design new_model2
new_model2 = Sequential()
new_model2.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))
new_model2.add(Conv1D(filters=32, kernel_size=3, padding='same',activation='relu')) # Add CNN conv layer
new_model2.add(MaxPooling1D(pool_size=2))
new_model2.add(LSTM(100))
new_model2.add(Dropout(0.3))  # Add a dropout layer with rate 0.3
new_model2.add(Dense(1, activation='sigmoid'))
new_model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(new_model2.summary())
hist = new_model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=64)

#Final evaluation of the new_model
scores = new_model2.evaluate(X_test, y_test, verbose=0)
print("Accuracy: %.2f%%" % (scores[1]*100))

#Plot learning curves
plt.subplot(2,1,1)
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('new_model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')

plt.subplot(2,1,2)
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('new_model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')

"""Learning curves show that difference between training accuracy and validation accuracy increased after adding a CNN layer, meaning the model is overfitting again. This is due to the model complexity increase, meaning the model has too many parameters. One way to address this is to reduce the number of layers or the number of neurons in each layer. This can help reduce the capacity of the model and prevent overfitting.  However, we had a slight accuracy increase (from 85% to 87%)."""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive')

# %shell jupyter nbconvert --to html '//content/gdrive/My Drive/Colab Notebooks/Lab 3.ipynb'